# Real vs. AI-Generated Image Classification

This project focuses on developing and evaluating various deep learning models to classify images as either authentic photographs or synthetically generated by AI. It utilizes models such as ResNet18, ResNet50, ViT Base Patch16, ConvNeXt V2 Tiny, and ConvNeXt V2 Base.

## Setup

It is recommended to use Python 3.12.x for this project, as specified in the provided `environment.yml` and `requirements.txt`.

### Option 1: Using Conda (Recommended for full environment replication)

1.  Create and activate the Conda environment using the `environment.yml` file:
    ```bash
    conda env create -f environment.yml
    conda activate exam_ml
    ```

### Option 2: Using pip and venv

1.  Create a Python virtual environment (e.g., with Python 3.12):
    ```bash
    python3.12 -m venv .venv
    ```
2.  Activate the environment:
    * On macOS/Linux: `source .venv/bin/activate`
    * On Windows: `.venv\Scripts\activate`
3.  Install the required packages using the `requirements.txt` file:
    ```bash
    pip install -r requirements.txt
    ```
4.  **Note:** Ensure you have compatible NVIDIA drivers and CUDA toolkit installed if you intend to use GPU acceleration. The scripts are configured to use CUDA if available.

## Project Structure and Files

The main scripts and important files involved in this project are:
*(Note: There are 5 versions of these files, one for each model architecture, mainly differing in model import and potentially some hyperparameters.)*

* `menu.py`: The main script to run, providing a menu to access different functionalities like preprocessing, training, and testing.
* `model_training_testing.py`: Contains the core functions for training the models, evaluating them on test/train datasets, and generating loss plots. 
* `preprocessing.py`: Includes functions for image preprocessing steps, such as resizing.
* `bad_img_detector.py`: Contains functions to detect and list corrupted or unreadable images in the dataset.
* `classifier_model.pth`: This is the generic name for the saved model weights after training. Each of the 5 models will produce its own `.pth` file when trained (they are all be saved as `classifier_model.pth` within their respective model-specific run). For evaluation using the menu, ensure the relevant `.pth` file is available.
* `list_of_bad_images.txt`: Generated by `bad_img_detector.py`, listing paths to corrupted images.
* `loss_plot.jpg`: Generated by `model_training_testing.py` after training, showing the training and validation loss curves.
* `environment.yml`: Conda environment specification file.
* `requirements.txt`: Pip requirements specification file.
* **Dataset:** The project requires a dataset of real and AI-generated images, we have provided a folder with the already preprocessed images which are organized into the following `resized_train/real`, `resized_train/fake`, `resized_test/real`, `resized_test/fake` subdirectories. The paths to this dataset need to be configured within `menu.py`.

## Running the Project

All operations can be managed through the `menu.py` script. Before running, ensure all Python scripts (`menu.py`, `model_training_testing.py` for the desired model, `preprocessing.py`, `bad_img_detector.py`, `classifier_model.pth`) are in the same current directory.

1.  **Customize File Paths:**
    * **Crucial Step:** Open `menu.py` and potentially `model_training_testing.py` (depending on which model you intend to work with).
    * Modify any hardcoded file paths for the dataset (input folders for original images, output folders for resized images) to match the locations on your local machine. The `menu.py` script contains path variables like `input_folder`, `output_folder`, `train` and `test_data` which **must be changed**.

2.  **Execute the Menu:**
    Run the `menu.py` script from your activated environment:
    ```bash
    python menu.py
    ```

3.  **Menu Options:**
    The menu will provide options to:
    * **1. Look for bad images:** This will run `bad_img_detector.py` on the specified dataset folders and create/update `list_of_bad_images.txt`.
        * You can choose to check train/real, train/fake, test/real, or test/fake images.
    * **2. Resize images from the dataset:** This will run `preprocessing.py` to resize images from the specified input folders and save them to output folders.
        * You can choose to resize train/real, train/fake, test/real, or test/fake images.
    * **3. Train/Test the model:**
        * **Train the model:** This will execute the training process defined in the associated `model_training_testing.py` script. Ensure the correct model architecture is being imported in that script. Upon completion, it will save the trained model (e.g., as `classifier_model.pth`) and generate `loss_plot.jpg`.
        * **Use the model on the train dataset:** Evaluates the saved model on the training data. Requires `classifier_model.pth` to be present.
        * **Use the model on the test dataset:** Evaluates the saved model on the test data. Requires `classifier_model.pth` to be present.
        * **Show Loss graph:** (This option in `menu.py` as described in the original file might attempt to display a pre-generated graph or re-generate it. The `model_training_testing.py` directly saves `loss_plot.jpg` after training).
    * **0. Exit:** Exits the menu.

### Important Considerations for Running:

* **Model Selection:** Due to there being 5 different models (ResNet18, ResNet50, ConvNeXt V2 Tiny, ConvNeXt V2 Base, ViT Base Patch16), the `model_training_testing.py` script and `menu.py` need to be specific to the model you want to work with, or be designed to allow selection. Typically, you would have separate training scripts or a way to specify the model architecture at runtime but this feature has not yet been added due to time constraints and as such the models have been divided into folders. Ensure the version of `model_training_testing.py` you are running corresponds to the model you intend to train/test.
* **Pre-existing Files:**
    * If you are only evaluating a pre-trained model, ensure the corresponding `classifier_model.pth` is in the current directory (or the path is correctly set).
    * The project deliverables already include output files like `list_of_bad_images.txt` and `loss_plot.jpg` for each model, so re-generating them might not be necessary if you only want to review results.
* **Dataset Path:** Accurate dataset paths are critical for all operations. Double-check these in `menu.py`.